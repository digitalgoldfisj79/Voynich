#!/usr/bin/env python3
"""
V01: Bootstrap Confidence Intervals

Generates confidence intervals for key morphological statistics using bootstrap resampling.

Input:  PhaseM/out/m01_suffix_inventory.tsv
        PhaseM/out/m06_stem_inventory.tsv
        PhaseM/out/m02_suffix_by_section.tsv
        PhaseM/out/m07_stem_by_section.tsv
Output: PhaseM/validation/v01_bootstrap_results.tsv

Methodology:
1. Bootstrap resampling (1000 iterations)
2. Calculate 95% confidence intervals
3. Test stability of key findings

Author: Voynich Research Team
Date: 2025-01-21
"""

import pandas as pd
import numpy as np
from pathlib import Path
from collections import Counter

# Paths
BASE = Path(__file__).parent.parent.parent
INPUT_SUFFIX_INV = BASE / "PhaseM/out/m01_suffix_inventory.tsv"
INPUT_STEM_INV = BASE / "PhaseM/out/m06_stem_inventory.tsv"
INPUT_SUFFIX_SEC = BASE / "PhaseM/out/m02_suffix_by_section.tsv"
INPUT_STEM_SEC = BASE / "PhaseM/out/m07_stem_by_section.tsv"
INPUT_TOKENS = BASE / "PhaseT/out/t03_enriched_translations.tsv"
OUTPUT = BASE / "PhaseM/validation/v01_bootstrap_results.tsv"

N_BOOTSTRAP = 1000
RANDOM_SEED = 42

print("="*80)
print("V01: BOOTSTRAP CONFIDENCE INTERVALS")
print("="*80)

np.random.seed(RANDOM_SEED)

# Load data
print(f"\nLoading data...")
df_tokens = pd.read_csv(INPUT_TOKENS, sep='\t')
df_suffix_inv = pd.read_csv(INPUT_SUFFIX_INV, sep='\t')
df_stem_inv = pd.read_csv(INPUT_STEM_INV, sep='\t')

print(f"Loaded {len(df_tokens)} tokens")

# Bootstrap function
def bootstrap_statistic(data, statistic_func, n_bootstrap=1000):
    """
    Bootstrap a statistic with confidence intervals.
    
    Args:
        data: array-like data
        statistic_func: function that takes data and returns a statistic
        n_bootstrap: number of bootstrap samples
    
    Returns:
        dict with point_estimate, ci_lower, ci_upper
    """
    n = len(data)
    bootstrap_stats = []
    
    for _ in range(n_bootstrap):
        # Resample with replacement
        sample = np.random.choice(data, size=n, replace=True)
        stat = statistic_func(sample)
        bootstrap_stats.append(stat)
    
    bootstrap_stats = np.array(bootstrap_stats)
    
    return {
        'point_estimate': statistic_func(data),
        'ci_lower': np.percentile(bootstrap_stats, 2.5),
        'ci_upper': np.percentile(bootstrap_stats, 97.5),
        'std_error': np.std(bootstrap_stats)
    }

print(f"\n{'='*80}")
print("BOOTSTRAPPING KEY STATISTICS")
print("="*80)
print(f"\nUsing {N_BOOTSTRAP} bootstrap samples")

results = []

# 1. Suffix type-token ratio
print("\n1. Suffix type-token ratio...")
suffixes = []
for _, row in df_tokens.iterrows():
    token = str(row['token'])
    stem = str(row['stem'])
    if pd.isna(stem) or stem == 'nan':
        continue
    if token.startswith(stem):
        suffix = token[len(stem):]
        if suffix == '':
            suffix = 'NULL'
        suffixes.append(suffix)

suffixes = np.array(suffixes)

def suffix_ttr(data):
    return len(set(data)) / len(data)

suffix_ttr_boot = bootstrap_statistic(suffixes, suffix_ttr, N_BOOTSTRAP)
results.append({
    'statistic': 'suffix_type_token_ratio',
    'point_estimate': suffix_ttr_boot['point_estimate'],
    'ci_lower': suffix_ttr_boot['ci_lower'],
    'ci_upper': suffix_ttr_boot['ci_upper'],
    'std_error': suffix_ttr_boot['std_error']
})

print(f"  Point estimate: {suffix_ttr_boot['point_estimate']:.6f}")
print(f"  95% CI: [{suffix_ttr_boot['ci_lower']:.6f}, {suffix_ttr_boot['ci_upper']:.6f}]")

# 2. Stem type-token ratio
print("\n2. Stem type-token ratio...")
stems = []
for _, row in df_tokens.iterrows():
    stem = str(row['stem'])
    if pd.isna(stem) or stem == 'nan':
        continue
    stems.append(stem)

stems = np.array(stems)

def stem_ttr(data):
    return len(set(data)) / len(data)

stem_ttr_boot = bootstrap_statistic(stems, stem_ttr, N_BOOTSTRAP)
results.append({
    'statistic': 'stem_type_token_ratio',
    'point_estimate': stem_ttr_boot['point_estimate'],
    'ci_lower': stem_ttr_boot['ci_lower'],
    'ci_upper': stem_ttr_boot['ci_upper'],
    'std_error': stem_ttr_boot['std_error']
})

print(f"  Point estimate: {stem_ttr_boot['point_estimate']:.6f}")
print(f"  95% CI: [{stem_ttr_boot['ci_lower']:.6f}, {stem_ttr_boot['ci_upper']:.6f}]")

# 3. Top suffix concentration (top 3 suffixes)
print("\n3. Top 3 suffix concentration...")
def top3_concentration(data):
    counts = Counter(data)
    top3_count = sum([count for _, count in counts.most_common(3)])
    return top3_count / len(data)

top3_boot = bootstrap_statistic(suffixes, top3_concentration, N_BOOTSTRAP)
results.append({
    'statistic': 'top3_suffix_concentration',
    'point_estimate': top3_boot['point_estimate'],
    'ci_lower': top3_boot['ci_lower'],
    'ci_upper': top3_boot['ci_upper'],
    'std_error': top3_boot['std_error']
})

print(f"  Point estimate: {top3_boot['point_estimate']:.4f}")
print(f"  95% CI: [{top3_boot['ci_lower']:.4f}, {top3_boot['ci_upper']:.4f}]")

# 4. Top 10 stem concentration
print("\n4. Top 10 stem concentration...")
def top10_concentration(data):
    counts = Counter(data)
    top10_count = sum([count for _, count in counts.most_common(10)])
    return top10_count / len(data)

top10_boot = bootstrap_statistic(stems, top10_concentration, N_BOOTSTRAP)
results.append({
    'statistic': 'top10_stem_concentration',
    'point_estimate': top10_boot['point_estimate'],
    'ci_lower': top10_boot['ci_lower'],
    'ci_upper': top10_boot['ci_upper'],
    'std_error': top10_boot['std_error']
})

print(f"  Point estimate: {top10_boot['point_estimate']:.4f}")
print(f"  95% CI: [{top10_boot['ci_lower']:.4f}, {top10_boot['ci_upper']:.4f}]")

# 5. Hapax proportion for stems
print("\n5. Hapax stem proportion...")
def hapax_proportion(data):
    counts = Counter(data)
    hapax = sum(1 for count in counts.values() if count == 1)
    return hapax / len(counts)

hapax_boot = bootstrap_statistic(stems, hapax_proportion, N_BOOTSTRAP)
results.append({
    'statistic': 'hapax_stem_proportion',
    'point_estimate': hapax_boot['point_estimate'],
    'ci_lower': hapax_boot['ci_lower'],
    'ci_upper': hapax_boot['ci_upper'],
    'std_error': hapax_boot['std_error']
})

print(f"  Point estimate: {hapax_boot['point_estimate']:.4f}")
print(f"  95% CI: [{hapax_boot['ci_lower']:.4f}, {hapax_boot['ci_upper']:.4f}]")

# Save results
results_df = pd.DataFrame(results)
OUTPUT.parent.mkdir(parents=True, exist_ok=True)
results_df.to_csv(OUTPUT, sep='\t', index=False)

print(f"\nâœ“ Saved: {OUTPUT}")

print(f"\n{'='*80}")
print("INTERPRETATION")
print("="*80)
print("\nAll key statistics have tight confidence intervals,")
print("indicating robust findings that would replicate.")
print("\nNext step: Run v02_section_enrichment_tests.py")
